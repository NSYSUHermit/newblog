blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::new_post_addin()
data_csv <- read.csv("C:\\Users\\User\\OneDrive - student.nsysu.edu.tw\\Educations\\NSYSU\\fu_chung\\bacterial\\20180111_CRE_46-non-CRE_49_Intensity.csv")
#preview the origin data
head(data_csv[,1:5],10)
blogdown:::new_post_addin()
blogdown:::insert_image_addin()
blogdown:::insert_image_addin()
blogdown:::insert_image_addin()
blogdown:::new_post_addin()
blogdown:::new_post_addin()
blogdown:::insert_image_addin()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::new_post_addin()
library(ropencc)
if (!require(ropencc))devtools::install_github("qinwf/ropencc")
library(ropencc)
blogdown:::serve_site()
blogdown:::insert_image_addin()
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)
if (!require(rvest))install.packages("rvest")
library(rvest)
if (!require(ropencc))devtools::install_github("qinwf/ropencc")
library(ropencc)
#read the html
bible <- read_html("https://heavenlyfood.cn/books/menu.php?id=2021")
#get the title
bible_title <- html_nodes(bible,"#title")
title <- html_text(bible_title)
title <- title[2:9]
trans <- converter(S2TWP)
title <- run_convert(trans, title) #trans simple chinese to traditional chinese
#get the chapter's url
url <- html_nodes(bible,"div a")
url <- data.frame(html_attr(url,"href"))
url <- t(data.frame(url[80:87,1])) #transpose the url data
for(i in c(1:length(title))){
#link to the chapter url
chapter_url <- paste0("https://heavenlyfood.cn/", url[i])
bible1 <- read_html(chapter_url)
#grab the content
bible_cont <- html_nodes(bible1,".cont")
cont <- html_text(bible_cont,trim = TRUE)
#trans simple Chinese to traditional Chinese
cont[1] <- title[i] #name the title
cont <- run_convert(trans, cont)
#output the txt for each chapter
nam <- paste(title[i],".txt", sep=" ")
write.table(cont,nam)
}
View(url)
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::new_post_addin()
這次要爬取的網站:  https://heavenlyfood.cn/books/menu.php?id=2021 (国度的操练为着教会的建造)
這個網頁是用簡體中文寫的，所以我會將最後輸出的語言轉換為繁體中文。
我將使用R-package："ropencc"來完成這項工作可以在Github上下載"ropencc"。
然後將章節輸出到每個文本文件。
這次要爬取的網站:  https://heavenlyfood.cn/books/menu.php?id=2021 (国度的操练为着教会的建造)
這個網頁是用簡體中文寫的，所以我會將最後輸出的語言轉換為繁體中文。
我將使用R-package："ropencc"來完成這項工作可以在Github上下載"ropencc"。
然後將章節輸出到每個文本文件。
blogdown:::insert_image_addin()
blogdown:::serve_site()
blogdown:::new_post_addin()
blogdown:::new_post_addin()
下面我們先令一個空個list來存放各年的資料，因為打擊跟投球資料是分開的表格，因此在存放至df前會有合併的動作 (這一步會run有點久，時間大約3-5分鐘)m
blogdown:::insert_image_addin()
blogdown:::insert_image_addin()
blogdown:::insert_image_addin()
blogdown:::new_post_addin()
data <- read.csv("C:\\Users\\User\\OneDrive - student.nsysu.edu.tw\\Educations\\2019暑期實習\\工研院\\資料科學_mlb\\mlb.csv")
row.names(data) <- data$Tm
data <- data[,-c(1,33,34,65)]
data$Playoff <- as.factor(data$Playoff)
data_lm <- data[,-c(62,63)]
attach(data)
library(tidyverse)
library(ggcorrplot)
#W,L
ggplot(data = data,mapping = aes(x = W.L.,color = Playoff))+
geom_freqpoly(binwidth = 0.1)
#correlation
data1 = as.data.frame(W.L.)
data1$Playoff <- data$Playoff
data1$Champion <- data$Champion
data1$BA <- data$BA
data1$ERA <- data$ERA
data1$BatAge <- data$BatAge
data1$PAge <- data$PAge
corr <- round(cor(data1), 1)
attach(data)
library(tidyverse)
library(ggcorrplot)
#W,L
ggplot(data = data,mapping = aes(x = W.L.,color = Playoff))+
geom_freqpoly(binwidth = 0.1)
#correlation
data1 = as.data.frame(W.L.)
data1$Playoff <- data$Playoff
data1$Champion <- data$Champion
data1$BA <- data$BA
data1$ERA <- data$ERA
data1$BatAge <- data$BatAge
data1$PAge <- data$PAge
#boxplot
boxplot(data1$W.L.,data1$Playoff)
attach(data)
library(tidyverse)
library(ggcorrplot)
#W,L
ggplot(data = data,mapping = aes(x = W.L.,color = Playoff))+
geom_freqpoly(binwidth = 0.1)
#correlation
data1 = as.data.frame(W.L.)
data1$Playoff <- data$Playoff
data1$Champion <- data$Champion
data1$BA <- data$BA
data1$ERA <- data$ERA
data1$BatAge <- data$BatAge
data1$PAge <- data$PAge
data <- read.csv("C:\\Users\\User\\OneDrive - student.nsysu.edu.tw\\Educations\\2019暑期實習\\工研院\\資料科學_mlb\\mlb.csv")
row.names(data) <- data$Tm
data <- data[,-c(1,33,34,65)]
data$Playoff <- as.factor(data$Playoff)
data_lm <- data[,-c(62,63)]
attach(data)
library(tidyverse)
library(ggcorrplot)
#W,L
ggplot(data = data,mapping = aes(x = W.L.,color = Playoff))+
geom_freqpoly(binwidth = 0.1)
#correlation
data1 = as.data.frame(W.L.)
data1$Playoff <- data$Playoff
data1$Champion <- data$Champion
data1$BA <- data$BA
data1$ERA <- data$ERA
data1$BatAge <- data$BatAge
data1$PAge <- data$PAge
#fit full model
fit_lm <- lm(W.L.~.,data = data_lm)
summary(fit_lm)
library(car)
vif(fit_bestlm, digits = 3)
vif_func<-function(in_frame,thresh=10,trace=T,...){
library(fmsb)
if(any(!'data.frame' %in% class(in_frame))) in_frame<-data.frame(in_frame)
#get initial vif value for all comparisons of variables
vif_init<-NULL
var_names <- names(in_frame)
for(val in var_names){
regressors <- var_names[-which(var_names == val)]
form <- paste(regressors, collapse = '+')
form_in <- formula(paste(val, '~', form))
vif_init<-rbind(vif_init, c(val, VIF(lm(form_in, data = in_frame, ...))))
}
vif_max<-max(as.numeric(vif_init[,2]), na.rm = TRUE)
if(vif_max < thresh){
if(trace==T){ #print output of each iteration
prmatrix(vif_init,collab=c('var','vif'),rowlab=rep('',nrow(vif_init)),quote=F)
cat('\n')
cat(paste('All variables have VIF < ', thresh,', max VIF ',round(vif_max,2), sep=''),'\n\n')
}
return(var_names)
}
else{
in_dat<-in_frame
#backwards selection of explanatory variables, stops when all VIF values are below 'thresh'
while(vif_max >= thresh){
vif_vals<-NULL
var_names <- names(in_dat)
for(val in var_names){
regressors <- var_names[-which(var_names == val)]
form <- paste(regressors, collapse = '+')
form_in <- formula(paste(val, '~', form))
vif_add<-VIF(lm(form_in, data = in_dat, ...))
vif_vals<-rbind(vif_vals,c(val,vif_add))
}
max_row<-which(vif_vals[,2] == max(as.numeric(vif_vals[,2]), na.rm = TRUE))[1]
vif_max<-as.numeric(vif_vals[max_row,2])
if(vif_max<thresh) break
if(trace==T){ #print output of each iteration
prmatrix(vif_vals,collab=c('var','vif'),rowlab=rep('',nrow(vif_vals)),quote=F)
cat('\n')
cat('removed: ',vif_vals[max_row,1],vif_max,'\n\n')
flush.console()
}
in_dat<-in_dat[,!names(in_dat) %in% vif_vals[max_row,1]]
}
return(names(in_dat))
}
}
library(car)
vif(fit_bestlm, digits = 3)
require(MASS)
require(clusterGeneration)
vif_func(in_frame=data_lm[,-32],thresh=5,trace=T)
library(leaps)
regfit.best<-regsubsets(W.L.~X.Bat+BatAge+AB+X2B+X3B+HR_x+SB+CS+BB_x+SO_x+OPS.+GDP+HBP_x+SH+SF+IBB_x+X.P+PAge+CG+tSho+cSho+SV+IP+IBB_y+HBP_y+BK+WP+ERA.+HR9+BB9+SO9+LOB_y,data_lm,nvmax=15)
regsumm<-summary(regfit.best)
which.min(regsumm$cp)
which.max(regsumm$rsq)
which.max(regsumm$adjr2)
par(mfrow = c(2,2))
plot(regsumm$cp)
points(which.min(regsumm$cp), regsumm$cp[which.min(regsumm$cp)], col = "red", cex = 2, pch = 20)
plot(regsumm$rsq)
points(which.max(regsumm$rsq), regsumm$rsq[which.max(regsumm$rsq)], col = "red", cex = 2, pch = 20)
plot(regsumm$adjr2)
points(which.max(regsumm$adjr2), regsumm$adjr2[which.max(regsumm$adjr2)], col = "red", cex = 2, pch = 20)
coef(regfit.full,15)
library(leaps)
regfit.best<-regsubsets(W.L.~X.Bat+BatAge+AB+X2B+X3B+HR_x+SB+CS+BB_x+SO_x+OPS.+GDP+HBP_x+SH+SF+IBB_x+X.P+PAge+CG+tSho+cSho+SV+IP+IBB_y+HBP_y+BK+WP+ERA.+HR9+BB9+SO9+LOB_y,data_lm,nvmax=15)
regsumm<-summary(regfit.best)
which.min(regsumm$cp)
which.max(regsumm$rsq)
which.max(regsumm$adjr2)
par(mfrow = c(2,2))
plot(regsumm$cp)
points(which.min(regsumm$cp), regsumm$cp[which.min(regsumm$cp)], col = "red", cex = 2, pch = 20)
plot(regsumm$rsq)
points(which.max(regsumm$rsq), regsumm$rsq[which.max(regsumm$rsq)], col = "red", cex = 2, pch = 20)
plot(regsumm$adjr2)
points(which.max(regsumm$adjr2), regsumm$adjr2[which.max(regsumm$adjr2)], col = "red", cex = 2, pch = 20)
fit_bestlm <- lm(W.L.~X.Bat + AB + HR_x + SO_x + OPS. + GDP + IBB_x + X.P + PAge +  tSho + SV+ IP+HBP_y+WP+ERA.,data_lm)
summary(fit_bestlm)
library(car)
vif(fit_bestlm, digits = 3)
par(mfrow = c(2,2))
plot(fit_bestlm)
blogdown:::insert_image_addin()
attach(data)
library(tidyverse)
library(ggcorrplot)
#W,L
ggplot(data = data,mapping = aes(x = W.L.,color = Playoff))+
geom_freqpoly(binwidth = 0.1)
#correlation
data1 = as.data.frame(W.L.)
data1$Playoff <- data$Playoff
data1$Champion <- data$Champion
data1$BA <- data$BA
data1$ERA <- data$ERA
data1$BatAge <- data$BatAge
data1$PAge <- data$PAge
corr <- round(cor(data1), 1)
View(data1)
str(data1)
attach(data)
library(tidyverse)
library(ggcorrplot)
#W,L
ggplot(data = data,mapping = aes(x = W.L.,color = Playoff))+
geom_freqpoly(binwidth = 0.1)
#correlation
data1 = as.data.frame(W.L.)
data1$Playoff <- as.numeric(data$Playoff)
data1$Champion <- data$Champion
data1$BA <- data$BA
data1$ERA <- data$ERA
data1$BatAge <- data$BatAge
data1$PAge <- data$PAge
corr <- round(cor(data1), 1)
ggcorrplot(corr, hc.order = TRUE, type = "lower", lab = TRUE)
attach(data)
library(tidyverse)
library(ggcorrplot)
#W,L
ggplot(data = data,mapping = aes(x = W.L.,color = Playoff))+
geom_freqpoly(binwidth = 0.1)
#correlation
data1 = as.data.frame(W.L.)
data1$Playoff <- as.numeric(data$Playoff)
data1$Champion <- data$Champion
data1$BA <- data$BA
data1$ERA <- data$ERA
data1$BatAge <- data$BatAge
data1$PAge <- data$PAge
corr <- round(cor(data1), 1)
ggcorrplot(corr, hc.order = TRUE, type = "lower", lab = TRUE)
library(tidyverse)
library(ggcorrplot)
#W,L
ggplot(data = data,mapping = aes(x = W.L.,color = Playoff))+
geom_freqpoly(binwidth = 0.1)
#correlation
data1 = as.data.frame(W.L.)
data1$Playoff <- as.numeric(data$Playoff)
data1$Champion <- data$Champion
data1$BA <- data$BA
data1$ERA <- data$ERA
data1$BatAge <- data$BatAge
data1$PAge <- data$PAge
corr <- round(cor(data1), 1)
ggcorrplot(corr, hc.order = TRUE, type = "lower", lab = TRUE)
library(tidyverse)
library(ggcorrplot)
#W,L
ggplot(data = data,mapping = aes(x = W.L.,color = Playoff))+
geom_freqpoly(binwidth = 0.1)
#correlation
data1 = as.data.frame(W.L.)
data1$Playoff <- as.numeric(data$Playoff)
data1$Champion <- data$Champion
data1$BA <- data$BA
data1$ERA <- data$ERA
data1$BatAge <- data$BatAge
data1$PAge <- data$PAge
corr <- round(cor(data1), 1)
ggcorrplot(corr, hc.order = TRUE, type = "lower", lab = TRUE)
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::new_post_addin()
blogdown:::new_post_addin()
## 讀取資料
這次僅使用測試資料做validation
## 建立初始化神經網路
引入models以及layers，並設定Activation Function使用Rectified Linear Unit
blogdown:::serve_site()
blogdown:::new_post_addin()
library(shiny)
runExample("01_hello")
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::new_post_addin()
blogdown:::insert_image_addin()
blogdown:::insert_image_addin()
●Cost-sensitive Classification：將一般機器學習的損失函數 (loss function) 改為成本導向的損失函數。舉個常見的AdaCost演算法，先回憶Adaboost演算法是通過反覆迭代，每一輪迭代學習到一個分類器，並根據當前分類器的表現更新樣本的權重其更新策略為正確分類樣本權重降低，錯誤分類樣本權重加大，最終的模型是多次迭代模型的一個加權線性組合，分類越準確的分類器將會獲得越大的權重。
blogdown:::serve_site()
blogdown:::new_post_addin()
blogdown:::insert_image_addin()
![](/post/2019-10-02-one-class-learning_files/3.GIF)
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::new_post_addin()
blogdown:::insert_image_addin()
blogdown:::serve_site()
blogdown:::serve_site()
