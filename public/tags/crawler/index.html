<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    
    <title>crawler | Lin&#39;s Blog</title>
    <link rel="stylesheet" href="/css/style.css" />
    <link rel="stylesheet" href="/css/fonts.css" />
    <link href="//cdn.bootcss.com/highlight.js/9.12.0/styles/github.min.css" rel="stylesheet">

  </head>

  <body>
    <nav class="header">
      <div class="banner">
<a href="/" class="text">
&Lfr;&Ifr;&Nfr;'&Sfr; &Bfr;&Lfr;&Ofr;&Gfr;
</a>
</div>

      <div class="head-meta">
      
        <span>crawler</span>
        <span>2019-10-23</span>
        
        <span>1 / 1</span>
      
      </div>
    </nav>


<div class="container">
<main class="list">


<section class="article-list">
  <div class="categories">
  
  
    <a href="/categories/python">Python</a>
  
  
  </div>
  <h1><a href="/post/2019/07/27/using-pandas-to-craw-mlb-team-data/">Using pandas to craw MLB team data</a></h1>
  <div class="date-author">
    <span class="author">Hermit
</span> / 
    <span class="date">2019-07-27</span>
  </div>
  <div class="summary">
    <a href="/post/2019/07/27/using-pandas-to-craw-mlb-team-data/">
    
    
    
    <div class="thumbnail"><img src="/post/2019-07-27-using-pandas-to-craw-mlb-team-data_files/ml2.PNG" alt="Thumbnail" /></div>
    
    
    
      
    
    這次參與工研院資料科學的課程，課程中分配的小組必須進行一個完整資料分析的報告，題目自訂。
因為球類的open data相對完整，基本上較少遺失值的問體，因此我們決定以mlb的球隊資料來當分析對象。 而主要分析目標則分為兩大類：第一、對例行賽勝率進行迴歸分析找出影響勝率的主因；第二、對&rdquo;明年是否進入季後賽&rdquo;做二項分類的預測。
這篇文章主要是介紹如何爬取並建立可分析的csv檔案。 主要使用pandas套件，並透過for迴圈去進行多個網頁的爬取，最後合併多年的投打資料，並以csv格式輸出。
因2004-2005之間有球隊更換隊名，因此為了&rdquo;方便&rdquo;資料合&hellip;
    </a>
  </div>
</section>

<section class="article-list">
  <div class="categories">
  
  
    <a href="/categories/r">R</a>
  
  
  </div>
  <h1><a href="/post/2019/05/23/web-crawler-on-simple-chinese-web/">Web crawler on simple Chinese web</a></h1>
  <div class="date-author">
    <span class="author">Hermit
</span> / 
    <span class="date">2019-05-23</span>
  </div>
  <div class="summary">
    <a href="/post/2019/05/23/web-crawler-on-simple-chinese-web/">
    
    
    
    <div class="thumbnail"><img src="/post/2019-05-02-web-crawler-on-simple-chinese-web_files/pi.PNG" alt="Thumbnail" /></div>
    
    
    
      
    
    我會在這次使用R-package:“rvest”來執行網路爬蟲。
這次要爬取的網站: https://heavenlyfood.cn/books/menu.php?id=2021 (国度的操练为着教会的建造)
這個網頁是用簡體中文寫的，所以我會將最後輸出的語言轉換為繁體中文。
我將使用R-package：“ropencc”來完成這項工作，它可以在Github上下載“ropencc”。
最後後將章節的故事輸出到每個txt文本文件，並且以章節名稱為檔案命名。
[&hellip;] if (!require(rvest))install.packages(&quot;rvest&quot;)&hellip;
    </a>
  </div>
</section>

</main>
<nav>
</nav>
</div>

<script async src="//yihui.name/js/center-img.js"></script>

<footer>

<div class="footer">
  <ul class="menu">
    
    <li><a href="/"><span data-hover="Home">Home</span></a></li>
    
    <li><a href="/categories/"><span data-hover="Categories">Categories</span></a></li>
    
    <li><a href="/tags/"><span data-hover="Tags">Tags</span></a></li>
    
    <li><a href="/about/"><span data-hover="Blogdown">Blogdown</span></a></li>
    
  </ul>
  
  <div class="copyright">&copy; <a href="/about1/">Lin</a> | <a href="https://github.com/NSYSUHermit">Github</a> | <a href="https://rpubs.com/JupiterHenry">Rpubs</a></div>
  
</div>
</footer>







</body>
</html>

